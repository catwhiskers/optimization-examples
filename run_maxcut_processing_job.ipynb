{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Numerical optimization jobs with your own dependencies\n",
    "\n",
    "Below, you walk through how to create a SageMaker processing container, and how to use a `ScriptProcessor` to run your own numerical optimization code within a container. You can provide your own dependencies inside this container to run your processing script with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile docker/Dockerfile\n",
    "\n",
    "FROM continuumio/anaconda3\n",
    "\n",
    "RUN pip install boto3 pandas scikit-learn pulp pyomo inspyred ortools scipy deap \n",
    "\n",
    "RUN conda install -c conda-forge ipopt coincbc glpk\n",
    "\n",
    "ENV PYTHONUNBUFFERED=TRUE\n",
    "\n",
    "ENTRYPOINT [\"python\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block of code builds the container using the `docker` command, creates an Amazon Elastic Container Registry (Amazon ECR) repository, and pushes the image to Amazon ECR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "ecr_repository = 'sagemaker-opt-container'\n",
    "tag = ':latest'\n",
    "processing_repository_uri = '{}.dkr.ecr.{}.amazonaws.com/{}'.format(account_id, region, ecr_repository + tag)\n",
    "\n",
    "# Create ECR repository and push docker image\n",
    "!docker build -t $ecr_repository docker\n",
    "!$(aws ecr get-login --region $region --registry-ids $account_id --no-include-email)\n",
    "!aws ecr create-repository --repository-name $ecr_repository\n",
    "!docker tag {ecr_repository + tag} $processing_repository_uri\n",
    "!docker push $processing_repository_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ScriptProcessor` class lets you run a command inside this container, which you can use to run your own script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile parameters.json\n",
    "\n",
    "{\n",
    "    \"node\": 20, \n",
    "    \"connect_prob\": 0.5, \n",
    "    \"parallel\": 12\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker \n",
    "session = sagemaker.session.Session()\n",
    "bucket = session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp parameters.json s3://$bucket/opt-example/parameters.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ScriptProcessor\n",
    "\n",
    "script_processor = ScriptProcessor(command=['python'],\n",
    "                image_uri=processing_repository_uri,\n",
    "                role=role,\n",
    "                instance_count=1,\n",
    "                instance_type='ml.m5.xlarge') #for larger jobs, we can switch instance type, for example, c5.4xlarge (ref: https://aws.amazon.com/ec2/instance-types/) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MaxCut - Using OR Tools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile preprocessing.py\n",
    "\n",
    "\n",
    "import json \n",
    "import networkx as nx\n",
    "from ortools.sat.python import cp_model\n",
    "\n",
    "\n",
    "def objective(optvar, edges, n_nodes):\n",
    "    exp = None \n",
    "    for j in range(0, n_nodes): \n",
    "        for i in range(0, n_nodes): \n",
    "            if j > i and edges[i][j] > 0: \n",
    "                if exp == None: \n",
    "                    exp = (1 - optvar[i][j]*int(edges[i][j]))\n",
    "                else:\n",
    "                    exp += (1 - optvar[i][j]*int(edges[i][j])) \n",
    "    return exp         \n",
    "\n",
    "input_f = open('/opt/ml/processing/input/parameters.json')\n",
    "data = json.load(input_f)\n",
    "n_nodes = data['node']\n",
    "p = data['connect_prob']  # probability of an edge\n",
    "workers_n = data['parallel']\n",
    "seed = 1967\n",
    "\n",
    "g = nx.erdos_renyi_graph(n_nodes, p=p, seed=seed)\n",
    "# nx.draw(g, with_labels=True, pos=positions, node_size=600)\n",
    "edges = nx.to_numpy_matrix(g)\n",
    "edges = edges.tolist()\n",
    "model = cp_model.CpModel()\n",
    "\n",
    "nodes = [None for i in range(0, n_nodes)] \n",
    "for i in range(0, n_nodes): \n",
    "    name = \"x\"+str(i)\n",
    "    nodes[i] = model.NewIntVar(-1, 1, name)\n",
    "\n",
    "optvar = [[None for i in range(0, n_nodes)] for j in range(0, n_nodes)]     \n",
    "for j in range(0, n_nodes):\n",
    "    for i in range(0, n_nodes):\n",
    "        if j > i:\n",
    "            name = \"x{}x{}\".format(str(i), str(j))\n",
    "            optvar[i][j] = model.NewIntVar(-1, 1, name)\n",
    "            model.AddMultiplicationEquality( optvar[i][j], [nodes[i], nodes[j]])\n",
    "            \n",
    "model.Maximize(objective(optvar, edges, n_nodes))            \n",
    "\n",
    "solver = cp_model.CpSolver()\n",
    "solution_printer = cp_model.VarArrayAndObjectiveSolutionPrinter(nodes)\n",
    "solver.parameters.num_search_workers = workers_n\n",
    "status = solver.Solve(model, solution_printer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "script_processor.run(code='preprocessing.py',\n",
    "                      inputs=[ProcessingInput(\n",
    "                        source='s3://{}/opt-example/parameters.json'.format(bucket),\n",
    "                        destination='/opt/ml/processing/input')],\n",
    "                      outputs=[ProcessingOutput(output_name='data',\n",
    "                                                source='/opt/ml/processing/data')])\n",
    "\n",
    "script_processor_job_description = script_processor.jobs[-1].describe()\n",
    "print(script_processor_job_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "We used various examples, front ends and solvers to solve numerical optimization problems using Sagemaker Processing. Next, try using Scipy.optimize, DEAP or Inspyred to explore other examples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
